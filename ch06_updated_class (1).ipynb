{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6장 데이터 로딩과 저장, 파일 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(12345)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"figure\", figsize=(10, 6))\n",
    "pd.options.display.max_colwidth = 75\n",
    "pd.options.display.max_columns = 20\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "plt.rcParams[\"font.family\"] = 'Malgun Gothic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. csv 텍스트 데이터\n",
    "## 1.1 csv파일 읽기\n",
    "* 판다스에서 CSV 파일을 읽기: pd.read_csv(path, encoding = 'utf-8') 함수를 사용\n",
    "    * path 인수 : 파일시스템에서의 위치, URL, 파일객체를 나타내는 문자열\n",
    "    * encoding 인수 - 유니코드 인코딩 종류을 지정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1) header(컬럼명)가 있는 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat examples/ex1.csv\n",
    "\n",
    "df = pd.read_csv(\"examples/ex1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2) header가 없는 파일 : 컬럼을 지정\n",
    "        * names 인수 - 열 이름 리스트\n",
    "        * header 인수 - 헤더가 없을 경우 None으로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"examples/ex2.csv\")\n",
    "\n",
    "names = [\"a\", \"b\", \"c\", \"d\", \"message\"]\n",
    "pd.read_csv(\"examples/ex2.csv\", names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3) 계층적 색인 지정하기\n",
    "        * index_col 인수 - 색인으로 사용할 열 번호나 이름, 계층적 색인을 지정할 경우 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = pd.read_csv(\"examples/csv_mindex.csv\",\n",
    "                     index_col=[\"key1\", \"key2\"])\n",
    "parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4) 여러 개의 공백으로 필드를 구분한 파일 \n",
    "        * sep 인수 - 필드을 구분하기 위해 사용할 정규 표현식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv(\"examples/ex3.txt\", sep=\"\\s+\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    5) 주석을 갖고 있는 파일\n",
    "        * skiprows 인수 - 파일의 시작부터 무시할 행 수 또는 무시할 행 번호가 담긴 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"examples/ex4.csv\", skiprows=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    6) 누락된 값이 있는 파일 : 비어 있는 문자열, NA, NULL을 NaN으로 출력 \n",
    "        * na_values 인수 - NA 값으로 처리할 값들의 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv(\"examples/ex5.csv\")\n",
    "result\n",
    "# 1) 누락된 값을 확인 : isna()함수 이용\n",
    "pd.isna(result)\n",
    "\n",
    "# 2) na_values -> 컬럼별 문자열 집합을 받아서 누락된 값 처리\n",
    "sentinels = {\"message\": [\"foo\", \"NA\"], \"something\": [\"two\"]}\n",
    "result = pd.read_csv(\"examples/ex5.csv\", na_values=sentinels)\n",
    "print(result)\n",
    "result.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    7) 텍스트 파일 조금씩 \n",
    "        * nrows 인수 - 파일의 첫 일부만 읽어올 때 처음 몇 줄을 읽을 것인지 지정 \n",
    "        * chunksize 인수 - TextParser 객체에서 사용할 한 번에 익을 파일의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.options.display.max_rows = 10\n",
    "result = pd.read_csv(\"examples/ex6.csv\")\n",
    "\n",
    "result = pd.read_csv(\"examples/ex6.csv\", nrows=5)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [예제]  ex6.csv 파일을 순회하면서 \"key\"열의 값을 세기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = pd.read_csv(\"examples/ex6.csv\", chunksize=1000)\n",
    "\n",
    "tot = pd.Series([], dtype='int64')\n",
    "for piece in chunker:\n",
    "    tot = tot.add(piece[\"key\"].value_counts(), fill_value=0)\n",
    "\n",
    "tot = tot.sort_values(ascending=False)\n",
    "tot\n",
    "tot[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. csv 텍스트 파일 저장하기\n",
    "* 판다스에서 CSV 파일을 저장하기: df.to_csv(path, encoding = 'utf-8') 함수를 사용\n",
    "    * path 인수 : 파일시스템에서의 위치, URL, 파일객체를 나타내는 문자열\n",
    "    * encoding 인수 - 유니코드 인코딩 종류을 지정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"examples/ex5.csv\")\n",
    "data1 = data[['a','b','d']]\n",
    "data1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv(\"examples/out.csv\")\n",
    "!cat examples/out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"examples/out.csv\", sep=\"|\") # 구분자 사용\n",
    "data.to_csv(\"examples/out.csv\", na_rep = \"NULL\") #누락된 값을 원하는 값으로 지정\n",
    "data.to_csv(\"examples/out.csv\", index=False, header=False)\n",
    "data.to_csv(\"examples/out.csv\", index=False, columns=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "!cat examples/out.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. JSON  데이터\n",
    "* JSON(JavaScript Object Notation)은 텍스트 데이터를 저장하고 전송하기 위한 일반적인 형식\n",
    "* 주로 웹에서 데이터를 전송하거나 저장하는 데 사용\n",
    "* JSON 파일은 일반적으로 텍스트 형식으로 작성되며, 사람과 기계 모두 이해하기 쉽다.\n",
    "* JSON 파일은 키-값 쌍의 모음으로 구성\n",
    "  * 키-값 쌍은 객체(object)라고도 하며, 중괄호 {} 로 묶는다.\n",
    "  * 배열(array)은 대괄호 [] 안에 값의 목록을 나열하여 정의."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 JSON 데이터 읽기/저장\n",
    "    * pandas의 to_json() -> 데이터프레임을 JSON 파일로 저\n",
    "    * read_json() -> JSON 파일에서 데이터프레임을 읽어오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [예제]  pandas의 to_json() 및 read_json() 메서드를 사용하여 데이터프레임을 JSON 파일로 저장하고 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. pandas 라이브러리 임포트\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 2. JSON 파일로 저장할 데이터프레임 생성\n",
    "data = {\n",
    "    \"name\": [\"John\", \"Alice\", \"Bob\"],\n",
    "    \"age\": [30, 25, 35],\n",
    "    \"city\": [\"New York\", \"Los Angeles\", \"Chicago\"]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 3. 데이터프레임을 JSON 파일로 저장\n",
    "df.to_json(\"examples/data.json\")\n",
    "\n",
    "# JSON 파일을 읽어와 데이터프레임으로 변환\n",
    "df_read = pd.read_json(\"examples/data.json\")\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nDataFrame from JSON file:\")\n",
    "print(df_read)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. HTML 데이터\n",
    "## 3.1 웹 스크래핑 - read_html()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* read_html() - html 문서 내 테이블 데이터 읽어 테이블 구조의 모든 데이터를 데이터프레임으로 저장해서 반환\n",
    "    * https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [예제] 미국 예금 보험 공사에서 부도 은행을 보여주는 HTML 문서 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "#tables = pd.read_html(\"examples/fdic_failed_bank_list.html\") \n",
    "tables = pd.read_html(\"https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/\")\n",
    "len(tables)\n",
    "print(type(tables))\n",
    "failures = tables[0]\n",
    "print(type(failures))\n",
    "failures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 컬럼명 수정하기\n",
    "failures.columns\n",
    "failures.columns = ['BankNameBank', 'CityCity', 'StateSt', 'CertCert',\n",
    "       'AcquiringInstitutionAI', 'ClosingDate', 'FundFund']\n",
    "failures.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 데이터 변환 : 문자열 -> datetime\n",
    "close_timestamps = pd.to_datetime(failures[\"ClosingDate\"])\n",
    "close_timestamps\n",
    "#3) 년도별 데이터 개수 추출\n",
    "close_timestamps.dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [실습] : 네이버 주식 데이터 가져오기 - read_html()\n",
    "* https://www.naver.com/ -> 증권 -> 국내증시 -> 시가총액\n",
    "    * https://finance.naver.com/sise/sise_market_sum.naver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install html5lib  lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 'euc-kr' 또는 'cp949'로 인코딩 설정하여 페이지 읽기 시도\n",
    "df_list = pd.read_html(\"https://finance.naver.com/sise/sise_market_sum.naver\",encoding='cp949')\n",
    "type(df_list)\n",
    "# 데이터프레임 확인\n",
    "for df in df_list:\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 탐색\n",
    "df = df_list[1]\n",
    "data = df[df['종목명'].notnull()] # 조건색인\n",
    "data\n",
    "data.head()\n",
    "data.to_csv(\"Naver_kospi.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 웹 스크래핑 - requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 웹 페이지 정보 가져오기 - requests 패키지 이용\n",
    "  * requests.get()\n",
    "  * requests.get().status_code\n",
    "  * requests.get().text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [예제] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. requests 모듈 설치하기\n",
    "#!pip install requests\n",
    "# 2. requests 모듈 임포트하기\n",
    "import requests\n",
    "#3. url 가져오기\n",
    "url = \"https://api.github.com/repos/pandas-dev/pandas/issues\"\n",
    "resp = requests.get(url)\n",
    "print(resp.status_code)\n",
    "resp.text\n",
    "\n",
    "# 4. json 내용을 딕셔너리로 변환\n",
    "data = resp.json() # json의 내용을 딕셔너리 형태로 변환한 객체을 반환\n",
    "print(type(data))\n",
    "data[0]['title']\n",
    "data[0].keys() # 키 정보 출력\n",
    "# 5. 딕셔너리를 DataFrame으로 생성하기\n",
    "issues = pd.DataFrame(data, columns=[\"number\", \"title\",\n",
    "                                      \"labels\", \"state\"])\n",
    "issues.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [문제] 네이버 블로그의 키워드 관련 검색 결과 텍스트 데이터 가져오기 - requests 모듈 사용시 한계점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# url = https://section.blog.naver.com/Search/Post.naver?pageNo=1&rangeType=ALL&orderBy=sim&keyword=%ED%8C%8C%EC%9D%B4%EC%8D%AC\n",
    "\n",
    "params = {\n",
    "    'pageNo' : 1,\n",
    "    'rangeType' : 'ALL',\n",
    "    'orderBy' : 'sim',\n",
    "    'keyword' : '파이썬'\n",
    "}\n",
    "\n",
    "response = requests.get('https://section.blog.naver.com/Search/Post.naver?', params=params)\n",
    "\n",
    "print(response.status_code) # HTTP GET 방식으로 URL 파라미터 값 전달\n",
    "print(response.url) # status_code 는 응답코드\n",
    "print(response.text) # text에는 HTML 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 웹 스크래핑 - beautifulsoup\n",
    "* 웹 페이지 정보 추출하기 - beautifulsoup 사용법 \n",
    "  * soup.select_one()\n",
    "  * soup.select()\n",
    "  * get_text()\n",
    "* 개발자 도구 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [문제] 네이버 지식iN의 검색어 관련 검색 결과 제목 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://kin.naver.com/search/list.naver?query=%ED%8C%8C%EC%9D%B4%EC%8D%AC'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html = response.text\n",
    "    # html -> beautifulsoup 객체로 변환\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 제목 한개 선택하여 텍스트 가져오기\n",
    "    title = soup.select_one('#s_content > div.section > ul > li:nth-child(1) > dl > dt > a')\n",
    "    print(title.get_text())\n",
    "\n",
    "    # 제목 여러 개 선택하여 텍스트 리스트 가져오기\n",
    "    titles = soup.select('#s_content > div.section > ul > li:nth-child(n) > dl > dt > a')\n",
    "    for title in titles:\n",
    "        print(title.get_text())\n",
    "else : \n",
    "    print(response.status_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 웹 스크래핑 - Selenium을 이용하여 사이트 자동화하기\n",
    "* selenium 사용법\n",
    "  1. 시스템의 OS 및 Chrome 브라우저의 버전 확인\n",
    "  2. Chrome 드라이버 다운로드 및 설치\n",
    "  3. 크롬 드라이버을 프로젝트 폴더에 저장 - 크롬 드라이버의 설치 경로\n",
    "     * from selenium import webdriver\n",
    "     * driver = webdriver.Chrome()\n",
    "* 동적으로 웹 페이지 정보 추출하기\n",
    "     * driver.get(\"웹주소\") \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [예제]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "# Chrome 브라우저 실행\n",
    "driver = webdriver.Chrome()\n",
    "# 웹페이지 열기\n",
    "url = \"httpss://www.google.com\"\n",
    "driver.get(url)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 selenium을 이용하여 타겟 웹사이트 실행하기/ 검색어의 제목과 url 출력\n",
    "크롬 브라우저를 이용하여 오픈에이아이 사용\n",
    "구글 개발자 도구 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [문제]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# Chrome 브라우저 실행\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 타겟 Google 홈페이지 열기\n",
    "url = \"https://www.google.com\"\n",
    "driver.get(url)\n",
    "\n",
    "# 페이지가 완전히 로드될 때까지 2초 대기\n",
    "time.sleep(5)\n",
    "\n",
    "try:\n",
    "    # 검색 상자 요소 찾기\n",
    "    search_box = driver.find_element(By.NAME, \"q\")\n",
    "\n",
    "    # 검색어 입력\n",
    "    search_query = \"OpenAI\"\n",
    "    search_box.send_keys(search_query)\n",
    "\n",
    "    # Enter 키를 눌러 검색 수행\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "    # 검색 결과가 로드될 때까지 5초 대기\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 검색 결과 추출\n",
    "    search_results = driver.find_elements(By.CSS_SELECTOR, \"div.g\") #<div class =\"g\"></div>\n",
    "\n",
    "    # 검색 결과의 제목(<h3></h3>)과 URL 인쇄\n",
    "    for result in search_results:\n",
    "        title = result.find_element(By.CSS_SELECTOR, \"h3\").text\n",
    "        url = result.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "        print(\"제목:\", title)\n",
    "        print(\"URL:\", url)\n",
    "        print()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"오류가 발생했습니다:\", e)\n",
    "\n",
    "finally:\n",
    "    # 브라우저 창 닫기\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[문제] 삼성전자의 시가총액의 일별 시세 데이터 가져오기\n",
    "* Selenium을 사용하여 웹 페이지를 열고, 페이지의 html을 가져와서 뷰티풀솦을 사용하여 일별 시세 데이터가 있는 테이블 찾기\n",
    "* 이후 데이터를 데이터 프레임으로 변환하여 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "#웹 드라이버 실행\n",
    "driver = webdriver.Chorom()\n",
    "\n",
    "#페이지 로딩 시간\n",
    "time.sleep(2)\n",
    "\n",
    "#타겟 홈페이지 url\n",
    "samsung_url= \"https://finance.naver.com/item/sise_day.naver?code=005930\"\n",
    "#페이지요청\n",
    "driver.get(samsung_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
